---
layout: post
title: "AI First 101: 从 Prompt Engineering 开始的 AI 指南"
subtitle: 以及 Prompt Engineering 实用技巧
date: 2025-10-11
author: BlackDn
header-img: img/21mon1_46.jpg
catalog: true
tags:
  - AI
---
> "我摊开心中愁，你只见眼前秋。"


# AI First 101: 从 Prompt Engineering 开始的 AI 指南
## 前言

正好最近上了个这方面的课程，系统性地学习一下 Prompt Engineering  
边学边记笔记，简单做了这篇文章  
最近困得要死，事情多又睡不够，难顶   
哦对了，祝大家国庆快乐，虽然已经过了。假期好短呜呜呜。   


## LLM 与 Gen AI

首先来做一下名词解释，理解一下 **大语言模型（LLM， Large Language Model）** 和 **生成式 AI（Generative AI，Gen AI）** 的关系。   
**Gen AI** 是一个宏大的概念，指能自动生成文本、图片、音频或视频内容的人工智能系统；而 **LLM** 是其中专注于自然语言处理的一个分支。所以简单来说是一种包含关系：**LLM 是 Gen AI 的一种实现形式**。    

| 项目 | Generative AI | Large Language Model |
|------|----------------|----------------------|
| **定义** | 能生成多模态内容的智能系统 | 专注文本理解与生成的语言模型 |
| **代表模型** | ChatGPT, Midjourney, Sora, DALL·E | GPT-4, Claude, Gemini, LLaMA |
| **应用范围** | 图像、语音、代码、视频等 | 聊天、总结、翻译、推理等 |
| **底层技术** | 深度学习 + 多模态训练 | Transformer + 大规模语料学习 |


## 提示词工程 Prompt Engineering

大部分情况下，我们都是通过 `ChatGPT`、`Gemini` 等LLM接触 Gen AI。在这些模型固定的情况下，输出结果的质量很大程度上取决于我们输入内容的质量。为了得到理想的输出结果，我们就需要不断改进和完善我们输入的内容，这就有了**提示词工程 Prompt Engineering**。

**Prompt** 直译就是**提示词**，指我们给 AI 输入的指令、问题、上下文等，用来告诉模型你希望它做什么。    
我们在许多资料中看到的 **Prompting** 就是指输入提示词的这一过程，而 **Prompt Engineering** 则是指通过精心设计和优化 prompt，以引导 AI 产生期望输出的技术与方法。    


### Prompt 分类

根据是否提供示例，我们可以将 Prompt 分为三类，具体内容如下：

| Prompt 类型            | 特点                          | 缺点                                                           |
| -------------------- | --------------------------- | ------------------------------------------------------------ |
| **Zero-shot Prompt** | - 快速，无需准备示例<br>- 适合简单或开放性任务 | - 输出质量可能不稳定，依赖上下文和已有知识库<br>- 对复杂任务理解可能不足，对特定案例精度缺失           |
| **One-shot Prompt**  | - 提供单一示例<br>- 输出结果一致性高，可预测  | - 需要人为提供示例<br>- 输出内容较 `Zero-shot` 更为单调<br>- 缺乏涵盖大部分情况的普适性    |
| **Few-shot Prompt**  | - 整合多个示例<br>- 对复杂任务的处理更可靠   | - 需要精力提供示例<br>- Prompt 可能过长，受 Token 限制影响<br>- 难以处理未提供示例的边界情况 |

当然，没有最好的 Prompt，只有最适合的 Prompt。还是需要具体情况具体分析，根据情景选择最合适的Prompt。

### Prompt Engineering 5 步架构

**Prompt Engineering** 的核心，在于清晰的上下文、以及持续优化。  
我们可以将 **Prompt Engineering** 的过程，即不断完善输入内容的过程，总结为以下5个步骤

| 步骤                 | 含义             | 示例                   |
| ------------------ | -------------- | -------------------- |
| **Task（任务）**       | 明确模型要完成什么任务    | “帮我写一篇关于人工智能伦理的博客草稿” |
| **Context（上下文）**   | 提供必要背景或约束条件    | “目标读者是大学生，语气友好”      |
| **References（参考）** | 提供格式、风格或示例     | “模仿TED演讲式语言风格”       |
| **Evaluate（评估）**   | 判断输出是否符合预期     | 检查逻辑性、准确性、流畅度        |
| **Iterate（迭代）**    | 基于反馈不断优化Prompt | 改写、增加上下文、拆分任务        |

## Prompt Engineering 实用技巧

### Custom Instructions：自定义指令

通过 **Custom Instructions**，你可以告诉模型“你是谁”与“你希望它如何回答”。这就像为 AI 建立 **“人格设定”**。  
举个例子，在输入问题或任务前，先告诉模型：

```
“你是一名理性且略带文艺风格的技术博主，擅长以通俗语言解释复杂概念。”
```

这类设置能帮助模型在整个会话中保持一致语气与目标。  

在这一阶段，我们通常会遵循以下几个原则：

| 原则                             | 含义          | 示例               |
| ------------------------------ | ----------- | ---------------- |
| **Clarity and Brevity（清晰与简洁）** | 明确任务，避免模糊描述 | “帮我写一个300字的项目总结” |
| **Consistency（一致性）**           | 保持语气与风格一致   | 使用统一口吻与格式        |
| **Relevance（相关性）**             | 聚焦目标任务      | 不提供无关背景          |
| **Regular Updates（定期更新）**      | 随任务更新指令     | 定期优化Prompt设定     |

### Memory Bank：记忆库

**Memory Bank** 让模型在多轮对话中保留上下文记忆，理解“对话连续性”。  这对于持续项目、学习计划或团队沟通尤为重要。    
使用 Memory Bank，能为模型的输出内容提供以下好处：

- **Maintain Continuity（保持连续性）**：在多轮交互中保持上下文一致，避免重复解释或丢失信息。
- **Enhance Relevance（提升相关性）**：根据历史对话生成更符合当前需求的回答。
- **Improve Efficiency（提高效率）**：减少重复说明，节省用户时间，提升协作体验。

### MCP Servers：模型控制协议与服务器

**MCP（Model Context Protocol）** 是一种为多模型协同与工具集成而设计的通信协议。它的目标是为生成式 AI 建立一个统一的“语言环境”，让不同模型、插件或外部工具能够高效、安全地交互。   
简单来说，**MCP 就像是 AI 的“通信桥梁”** ， 它定义了不同 AI 模块（如语言模型、数据工具、知识库、外部 API）如何共享上下文、执行任务与返回结果。

而 **MCP Servers** 则是采用了 MCP 的服务器，负责处理多个 AI 模型之间的请求与响应、管理外部数据或工具调用、以及保证通信过程的安全与可控性。

1. 客户端向 MCP Server 发送任务请求（如数据检索、调用 API、执行脚本）；
2. **MCP Server** 解析请求并路由到合适的模块或模型；
3. 执行任务后，Server 将结果回传给 Client；
4. Client 再将结果整合进用户的对话或应用逻辑中。

使用 **MCP Servers** 后意味着，AI 不再是“孤立的模型”，而是一个可扩展的系统，可以同时调用多个外部服务和智能代理。   

其具体优点如下：

| 优点                              | 含义                                  |
| ------------------------------- | ----------------------------------- |
| **Unified Communication（统一通信）** | 不同模型与外部系统可以通过标准化协议无缝对接，避免重复开发与复杂集成。 |
| **Modular Integration（模块化集成）**  | 支持将不同功能（如检索、分析、生成）模块化，灵活组合。         |
| **Enhanced Security（增强安全性）**    | 通过协议层安全控制与权限分级，确保数据传输与外部调用的合规与可追溯。  |
| **Improved Debugging（优化调试能力）**  | 标准化通信结构让开发者更容易跟踪模型交互、识别问题来源并优化流程。   |

### Prompt Chaining：提示链

**Prompt Chaining** 是将多个 Prompt 依次串联，实现渐进式提问和输出，使模型在每一步的输出基础上继续处理下一步任务。   
可以理解为`“分解问题 → 逐步求解”`的策略。举个例子：

```
需求：生成一段说明文概括某文章的内容

第一步：总结文章核心观点
Prompt：“请总结下面文章的主要观点。”

第二步：将总结转换为推理流程
Prompt: “根据总结内容，列出文章的逻辑步骤。”

第三步：生成最终输出
Prompt: “将逻辑步骤转化为一段连贯的说明文。”
```

这种技巧的优点是：能处理复杂任务，将大问题拆解为小步骤；提高生成内容的逻辑性和一致性等。  
缺点也有：对用户拆分问题和流程设计的要求较高；某一步的错误可能会影响最终结果等。

### Tree of Thought：思维树

**Tree of Thought（ToT）** 是一种多路径推理方法，它通过生成多个思路（思维节点），在模型内部形成“思维树”，再选择最优路径生成答案。  
可以理解为“模拟人类多方案思考，再选最佳方案”。举个例子：

```
需求：求解一道数学题

第一步：让模型生成多种可能解法（各为一个思维节点）
Prompt：“请使用不同的方法求解这道题。”

第二步：对每个思维节点进行评估
Prompt：“请对每个方法进行评估，列出各自的优缺点。”

第三步：选择最优或最合理的解法输出
Prompt：“考虑到xxx等因素，请选择最适合的解法”
```

这种技巧的优点是：提升复杂推理和多步骤问题的正确率；能模拟人类思考的多路径探索。    
局限性则是：需要更多计算资源；设计和调优较为复杂。

## 局限性和伦理考量


### 六大局限性

由于模型在训练时，因为各种因素，用以训练的数据做不到绝对充分且客观，因此会导致模型的输出存在各种局限性。  
下面这张表总结了当前 **LLM / Gen AI** 的六大局限性及其含义：

| 英文名                                        | 中文名      | 代表含义                    |
| ------------------------------------------ | -------- | ----------------------- |
| **Hallucination**                          | 幻觉       | AI 自信地“编造”事实，比如虚构论文或网址。 |
| **Potential Bias & Discrimination**        | 潜在偏见与歧视  | 模型继承了人类数据中的偏见。          |
| **Outdated Training Data**                 | 数据过时     | 模型知识截止于训练时间，无法访问最新信息。   |
| **Lack of Human & Emotional Intelligence** | 缺乏情感智能   | 无法理解幽默、情绪或人类复杂动机。       |
| **Token Limits**                           | Token 限制 | 模型对话上下文容量有限，长文本可能丢失记忆。  |
| **Lack of Logical Reasoning**              | 缺乏逻辑推理   | 在复杂逻辑或数学推演中易出错。         |

### 伦理考量

由于局限性的存在，可能会导致输出的结构存在各种伦理上的问题。  
在使用生成式 AI 时，我们应注意以下伦理维度：

- **Human Oversight（人类监督）**：AI 不能完全取代人类判断，应始终由人做最终决策。  
- **Code Rights（代码权利）**：明确生成内容的版权归属，尤其在商业场景中。  
- **Bias Prevention（偏见防止）**：识别和纠正模型潜在偏见，避免误导与歧视。


## 参考


1. [Google's 9 Hour AI Prompt Engineering Course In 20 Minutes](https://www.youtube.com/watch?v=p09yRj47kNM&ab_channel=TinaHuang)
2. [OpenAI - Introduction to Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)  
3. [LangChain Docs - Advanced Prompting Strategies](https://python.langchain.com/docs/modules/model_io/prompts/)
